{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad57360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the file: /Users/haotianshen/Desktop/CS5002/CS5002 Final Project/out.dblp-author-all.txt\n",
      "The minimum number of authors per paper is 1; The maximum number of authors per paper is 119; The average number of authors per paper is 2.1621729185155556.\n",
      "The minimum number of papers per author is 1; The maximum number of papers per author is 951; The average number of papers per author is 6.066024085907479.\n",
      "The set of authors for X-index of 13 are the following author IDs:\n",
      "author ID: 1021195\n",
      "author ID: 1199180\n",
      "author ID: 1199787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The DBLP Publication Network\n",
    "\n",
    "# 1. Problem statement:\n",
    "\n",
    "# The following datasets, provided on Canvas, contain bipartite graphs where one set of nodes (vertices) are authors\n",
    "# and the other set are academic papers. Each edge (a, p) connects an author a to a paper p.\n",
    "# out.dblp_author-short.txt\n",
    "# out.dblp_author-medium.txt\n",
    "# out.dblp_author-long.txt\n",
    "# out.dblp_author-all.txt\n",
    "# The short dataset contains 1,000 edges, the medium 10,000 edges, the long version 100,000 edges, and the \"all\"\n",
    "# version has all the edges.\n",
    "# Note: The network is encoded with two numbers per line separated by spaces. You will need to open and read the file,\n",
    "# and then turn the read data into a meaningful format. If you use Python, you should be able to use built-in method\n",
    "# split to get a list of numbers. The numbers at even indices (starting at 0) are authors, and the numbers at odd\n",
    "# indices are publications. You will want to be mindful not to do things that take a lot of operations or memory.\n",
    "\n",
    "# a) Find the minimum, maximum, and average number authors per paper.\n",
    "# b) Find the minimum, maximum, and average number of papers per author.\n",
    "# c) Find the (not necessarily unique) author who has written the most papers. Call this author X. An author other\n",
    "# than X has an X-index of 1 if she has co-authored at least one paper with X. An author has an X-index of 2 if she\n",
    "# does not have an X-index of 1, but has co-authored a paper with someone who has an X-index of 1. Similarly, you can\n",
    "# define having an X-index of 3, 4, etc.\n",
    "# Write a function that produces the set of authors for some given index, n.\n",
    "\n",
    "# 2. Mathematical description of the solution:\n",
    "\n",
    "# The solution can be broken down into three parts:\n",
    "# (1) creating the adjacency list to represent the network. Each edge (a, p) from an author a to a paper p can be seen\n",
    "# as an edge in the adjacency list. We can establish two adjacency lists, one using author as the key and set of papers\n",
    "# for this author as the value, one using paper as key and set of authors for this paper as the value.\n",
    "# (2) Once the graphs are established, we can calculate the minimum, the maximum, and the average number of papers per\n",
    "# author and number of authors per paper.\n",
    "# (3) Using the graph we created, we can obtain a list of X authors by comparing whether the length of the set of papers\n",
    "# equals to the maximum paper per author. We will use a BFS algorithm to process the graph. The initial array containing\n",
    "# all the X authors will be the initial queue in the iterative BFS algorithm. Currently, we are at level 0, because X-index\n",
    "# 1 indicates the co-author of X author, so X author can be set to level 0. We need to process the graph level by level,\n",
    "# starting from the X author, so this makes sure that we do not go back to the previous level. This logic satisfies the\n",
    "# problem statements that author with X-index of 2 does not have an X-index of 1, but only co-author with someone who\n",
    "# has X-index of 1. In order to process the graph level by level, we need to know how many elements are at the current\n",
    "# level. Thus, we use a variable cur_level_size to save for the number of elements in the queue before we pop anything\n",
    "# from the queue. For each value that is already in the queue, we label them as visited, so we do not go back to the author\n",
    "# that we already processed and create an infinite loop. To get the co-author of our current author, we first loop through\n",
    "# all the papers published by this author, and for each paper, look up all its authors. If these authors are not already\n",
    "# visited, we can add them to the queue. If the current level has finished processing, increment the level variable by 1\n",
    "# and go to process the next level. Once the level is equal to the desired X-index of n, we add all the elements in the queue\n",
    "# into an array and return it.\n",
    "\n",
    "# 3. Observations and insights drawn from your approach:\n",
    "\n",
    "# The BFS algorithm is implemented iteratively using a queue data structure. A queue is a FIFO data structure, which means\n",
    "# that anything added first to the queue will be popped out of the queue first. We are able to process the graph level\n",
    "# by level by leveraging the characteristics of queue. The time complexity of the algorithm to calculate maximum, minimum,\n",
    "# and average values are O(V+E). The BFS algorihtm time complexity is O(V+E) as well, so the time complexity of the whole \n",
    "# algorithm is O(V+E), where V represents the number of vertex (author and paper), and E represents the number of edges \n",
    "# (from author to paper and from paper to author).\n",
    "\n",
    "# 4. Executable, commented, and clear code:\n",
    "\n",
    "# See below for the implementation of the algorithm in Python. I have tested the program using the short, medium, and long \n",
    "# version, but the program runs really slow on the all version and does not give an input probably limited by my laptop.\n",
    "\n",
    "import math\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "\n",
    "# Read from the publication data file and parse the information to two adjacency list. The first adjacency list\n",
    "# expressed using two dictionary in Python.\n",
    "# author_to_paper_adj_list: key is author, value is a set of paper published by this author.\n",
    "# paper_to_author_adj_list: key is paper, value is a set of authors for this paper.\n",
    "file_path = Path('out.dblp-author-all.txt')\n",
    "author_to_paper_adj_list = {}\n",
    "paper_to_author_adj_list = {}\n",
    "with open(file_path, 'r') as publication_info_file:\n",
    "    for line in publication_info_file:\n",
    "        line_arr = line.split()\n",
    "        author, paper = line_arr\n",
    "        author = int(author)\n",
    "        paper = int(paper)\n",
    "        if author in author_to_paper_adj_list:\n",
    "            author_to_paper_adj_list[author].add(paper)\n",
    "        else:\n",
    "            author_to_paper_adj_list[author] = {paper}\n",
    "\n",
    "        if paper in paper_to_author_adj_list:\n",
    "            paper_to_author_adj_list[paper].add(author)\n",
    "        else:\n",
    "            paper_to_author_adj_list[paper] = {author}\n",
    "\n",
    "# After the two adjacency lists have been created. Go through each one of them, and get the maximum and minimum value\n",
    "# from each adjacency list. While looping through the dictionary, also keep track of the sum of authors and papers in\n",
    "# order to calculate the average value after the for loop. The average authors per paper is calculated as the sum of\n",
    "# number of authors for all the papers divided by the number of papers. The average papers per author is calculated in\n",
    "# the same manner.\n",
    "min_papers_per_author = math.inf\n",
    "max_papers_per_author = -1\n",
    "sum_of_papers_per_author = 0\n",
    "for author in author_to_paper_adj_list:\n",
    "    cur_papers_for_author = len(author_to_paper_adj_list.get(author))\n",
    "    sum_of_papers_per_author += cur_papers_for_author\n",
    "    min_papers_per_author = min(cur_papers_for_author, min_papers_per_author)\n",
    "    max_papers_per_author = max(cur_papers_for_author, max_papers_per_author)\n",
    "\n",
    "\n",
    "average_papers_per_author = sum_of_papers_per_author / len(author_to_paper_adj_list)\n",
    "\n",
    "min_authors_per_paper = math.inf\n",
    "max_authors_per_paper = -1\n",
    "sum_of_authors_per_paper = 0\n",
    "for paper in paper_to_author_adj_list:\n",
    "    cur_authors_for_paper = len(paper_to_author_adj_list.get(paper))\n",
    "    sum_of_authors_per_paper += cur_authors_for_paper\n",
    "    min_authors_per_paper = min(cur_authors_for_paper, min_authors_per_paper)\n",
    "    max_authors_per_paper = max(cur_authors_for_paper, max_authors_per_paper)\n",
    "\n",
    "average_authors_per_paper = sum_of_authors_per_paper / len(paper_to_author_adj_list)\n",
    "\n",
    "# Print out the result as two formatted strings.\n",
    "print(\"For the file: {}\".format(\"/Users/haotianshen/Desktop/CS5002/CS5002 Final Project/out.dblp-author-all.txt\"))\n",
    "print(\"The minimum number of authors per paper is {}; The maximum number of authors per paper is {}; The average number of authors per paper is {}.\".format(\n",
    "    min_authors_per_paper, max_authors_per_paper, average_authors_per_paper))\n",
    "print(\"The minimum number of papers per author is {}; The maximum number of papers per author is {}; The average number of papers per author is {}.\".format(\n",
    "    min_papers_per_author, max_papers_per_author, average_papers_per_author))\n",
    "\n",
    "\n",
    "# Function find_all_authors_with_X_index_of_n use the BFS algorithm to find the author with X-index of n. It will take\n",
    "# in three parameters, X-index of n, author_to_paper adjacency list, paper_to_author adjacency list. A visited array\n",
    "# will be maintained to keep track of the authors that are already visited because an author with a higher X-index does\n",
    "# not have a smaller X-index. Process the adjacency list level by level, starting from the level containing author X.\n",
    "# Once we reach the level of X-index of n, we add the all the authors at this level into an array and return the result.\n",
    "def find_all_authors_with_X_index_of_n(n, X_authors, author_to_paper_adj_list, paper_to_author_adj_list):\n",
    "    X_authors = deque(X_authors)\n",
    "    visited = set()\n",
    "    authors_with_X_index_of_n = []\n",
    "    level = 0\n",
    "    \n",
    "    for init_author in X_authors:\n",
    "        if init_author not in visited:\n",
    "            visited.add(init_author)\n",
    "\n",
    "    while X_authors:\n",
    "        cur_level_size = len(X_authors)\n",
    "        while cur_level_size > 0:\n",
    "            author = X_authors.popleft()\n",
    "            visited.add(author)\n",
    "\n",
    "            if level == n and author not in authors_with_X_index_of_n:\n",
    "                authors_with_X_index_of_n.append(author)\n",
    "\n",
    "            for paper in author_to_paper_adj_list[author]:\n",
    "                co_authors = paper_to_author_adj_list[paper]\n",
    "                for co_author in co_authors:\n",
    "                    if co_author not in visited:\n",
    "                        X_authors.append(co_author)\n",
    "                        visited.add(co_author)\n",
    "            cur_level_size = cur_level_size - 1\n",
    "\n",
    "        level = level + 1\n",
    "\n",
    "    return authors_with_X_index_of_n\n",
    "\n",
    "# Function pint_authors_with_X_index_of_n print out the authors with X-index of n to the console. If there is no authors\n",
    "# with X-index of n, then the function print out a message stating that. Otherwise, the function print out the author\n",
    "# ID whose X-index is n.\n",
    "def print_authors_with_X_index_of_n(n, authors_with_X_index_of_n):\n",
    "    print(\"The set of authors for X-index of {}\".format(n) +\n",
    "          \" are the following author IDs:\")\n",
    "    if len(authors_with_X_index_of_n) == 0:\n",
    "        print(\"There is no author with X-index of {}. Please try a smaller X-index value!\".format(n))\n",
    "        return\n",
    "    for author in authors_with_X_index_of_n:\n",
    "        print(\"author ID: {}\".format(author))\n",
    "\n",
    "# Get all the authors with the maximum papers published. These are authors X, which can be either one or more than one.\n",
    "def get_X_authors(author_to_paper_adj_list, max_papers_per_author):\n",
    "    X_authors = []\n",
    "    for author in author_to_paper_adj_list:\n",
    "        if len(author_to_paper_adj_list.get(author)) == max_papers_per_author:\n",
    "            X_authors.append(author)\n",
    "    return X_authors\n",
    "\n",
    "\n",
    "# Test the code with X-index of 13. \n",
    "n_index_1 = 13\n",
    "X_authors = get_X_authors(author_to_paper_adj_list, max_papers_per_author)\n",
    "authors_with_X_index_of_n = find_all_authors_with_X_index_of_n(\n",
    "    n_index_1, X_authors, author_to_paper_adj_list, paper_to_author_adj_list)\n",
    "authors_with_X_index_of_n.sort()\n",
    "print_authors_with_X_index_of_n(n_index_1, authors_with_X_index_of_n)\n",
    "print()\n",
    "\n",
    "# Commented out for test with X-index of 1 and 2 for the short version.\n",
    "\n",
    "# n_index_2 = 2\n",
    "# X_authors = get_X_authors(author_to_paper_adj_list, max_papers_per_author)\n",
    "# authors_with_X_index_of_n = find_all_authors_with_X_index_of_n(\n",
    "#     n_index_2, X_authors, author_to_paper_adj_list, paper_to_author_adj_list)\n",
    "# authors_with_X_index_of_n.sort()\n",
    "# print_authors_with_X_index_of_n(n_index_2, authors_with_X_index_of_n)\n",
    "# print()\n",
    "\n",
    "# n_index_3 = 3\n",
    "# X_authors = get_X_authors(author_to_paper_adj_list, max_papers_per_author)\n",
    "# authors_with_X_index_of_n = find_all_authors_with_X_index_of_n(\n",
    "#     n_index_3, X_authors, author_to_paper_adj_list, paper_to_author_adj_list)\n",
    "# authors_with_X_index_of_n.sort()\n",
    "# print_authors_with_X_index_of_n(n_index_3, authors_with_X_index_of_n)\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5e7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
